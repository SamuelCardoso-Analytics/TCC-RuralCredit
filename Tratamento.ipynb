{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b8ddfbc-eeae-49a7-b08e-805b0c10a813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.types import NumericType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f99a8c8-a03d-4b5a-a692-e3f3f4d5aaf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Tratamento - Z-Score e Outiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8b7d02e8-b1fe-4fc1-bd56-20cb61b39e8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_main = spark.table('workspace.default.tb_demanda_credito') \\\n",
    "    .join(spark.table('workspace.default.tb_fatores_agricolas'), on='Date_event', how='left') \\\n",
    "    .join(spark.table('workspace.default.tb_variaveis_macroeconomicas'), on='Date_event', how='left')\n",
    "\n",
    "df_padronizado = df_main\n",
    "\n",
    "colunas_numericas = [\n",
    "    field.name\n",
    "    for field in df_main.schema.fields\n",
    "    if isinstance(field.dataType, NumericType)\n",
    "]\n",
    "\n",
    "for coluna in colunas_numericas:\n",
    "    stats = df_main.select(\n",
    "        functions.mean(coluna).alias('media'),\n",
    "        functions.stddev(coluna).alias('desvio')\n",
    "    ).collect()[0]\n",
    "\n",
    "    df_padronizado = df_padronizado.withColumn(f'{coluna}_padronizado',\n",
    "        functions.round((functions.col(coluna) - stats['media']) / stats['desvio'], 2))\n",
    "\n",
    "for coluna in colunas_numericas:\n",
    "    df_padronizado = df_padronizado.drop(coluna).withColumnRenamed(f'{coluna}_padronizado', coluna)\n",
    "\n",
    "display(df_padronizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "18c16a67-9ade-4995-8cf3-3e5cb16b8a72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for coluna in colunas_numericas:\n",
    "\n",
    "    Q1, Q3 = df_padronizado.approxQuantile(coluna, [0.25, 0.75], 0.01)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - (1.5 * IQR)\n",
    "    limite_superior = Q3 + (1.5 * IQR)\n",
    "    results.append({\n",
    "        'coluna': coluna,\n",
    "        'Q1': round(Q1, 2),\n",
    "        'Q3': round(Q3, 2),\n",
    "        'IQR': round(IQR, 2),\n",
    "        'limite_inferior': round(limite_inferior, 2),\n",
    "        'limite_superior': round(limite_superior, 2)\n",
    "    })\n",
    "\n",
    "df_outliers = pd.DataFrame(results)\n",
    "display(df_outliers)\n",
    "\n",
    "df_pd = df_padronizado.select(['Date_event'] + colunas_numericas).toPandas()\n",
    "\n",
    "for _, row in df_outliers.iterrows():\n",
    "    coluna = row['coluna']\n",
    "    limite_inferior = row['limite_inferior']\n",
    "    limite_superior = row['limite_superior']\n",
    "\n",
    "for coluna in colunas_numericas:\n",
    "    plt.figure(figsize=(10, 6)) \n",
    "    plt.scatter(df_pd['Date_event'], df_pd[coluna], color='blue', alpha=0.5)\n",
    "    plt.axhline(y=limite_inferior, color='red', linestyle='--', label='Limite Inferior')\n",
    "    plt.axhline(y=limite_superior, color='green', linestyle='--', label='Limite Superior')\n",
    "    plt.xlabel('Date_event')\n",
    "    plt.ylabel(coluna)\n",
    "    plt.title(f'Gráfico de Dispersão - {coluna}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fcc9961a-352f-419d-9766-af42dd44d907",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[],\"syncTimestamp\":1764214960711}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "colunas_para_limitar = ['Qty_credit', 'Value_credit', 'Rate_credit', 'Qty_cra', 'Price_coffee', 'Price_cotton', 'Total_rainfall', 'Atmospheric_pressure', 'Temperature', 'Agri_pib', 'Rate_igpm', 'Price_dolar']\n",
    "\n",
    "df_outliers_filtrado = df_outliers[df_outliers['coluna'].isin(colunas_para_limitar)]\n",
    "\n",
    "df_normalizado = df_padronizado\n",
    "\n",
    "for _, row in df_outliers_filtrado.iterrows():\n",
    "    coluna = row['coluna']\n",
    "    limite_superior = row['limite_superior']\n",
    "    limite_inferior = row['limite_inferior']\n",
    "\n",
    "    df_normalizado = df_normalizado.withColumn(\n",
    "        coluna,\n",
    "        functions.when(functions.col(coluna) > limite_superior, limite_superior) \\\n",
    "            .when(functions.col(coluna) < limite_inferior, limite_inferior) \\\n",
    "            .otherwise(functions.col(coluna))\n",
    "    )\n",
    "\n",
    "display(df_normalizado)\n",
    "\n",
    "df_normalizado.write.mode(\"overwrite\").saveAsTable('workspace.default.tb_dados_normalizados')\n",
    "df_pd = df_normalizado.select('*').toPandas()\n",
    "\n",
    "for _, row in df_outliers_filtrado.iterrows():\n",
    "    coluna = row['coluna']\n",
    "    limite_inferior = row['limite_inferior']\n",
    "    limite_superior = row['limite_superior']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df_pd['Date_event'], df_pd[coluna], color='blue', alpha=0.5)\n",
    "    plt.axhline(y=limite_inferior, color='red', linestyle='--', label='Limite Inferior')\n",
    "    plt.axhline(y=limite_superior, color='green', linestyle='--', label='Limite Superior')\n",
    "    plt.xlabel('Date_event')\n",
    "    plt.ylabel(coluna)\n",
    "    plt.title(f'Gráfico de Dispersão - {coluna}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Tratamento",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
